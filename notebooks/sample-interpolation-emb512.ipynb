{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import random, sys, math, gzip, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "from dataloader.nsynthdataset import NSynthDataSet\n",
    "from util import util\n",
    "from transformer.transformers import GTransformer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = util.get_config('../config/config.json')\n",
    "data_dir = config['data_dir']\n",
    "sample_rate = config['sample_rate']\n",
    "batch_size = config['batch_size']\n",
    "lr = config['lr']\n",
    "lr_warmup = config['lr_warmup']\n",
    "epochs = config['epochs']\n",
    "\n",
    "sample_length = config['sample_length']\n",
    "embedding_size = config['embedding_size'] \n",
    "num_heads = config['num_heads']\n",
    "depth = config['depth']\n",
    "num_tokens = config['num_tokens']\n",
    "\n",
    "lower_pitch_limit = config['lower_pitch_limit']\n",
    "upper_pitch_limit = config['upper_pitch_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_interp = GTransformer(emb=embedding_size, heads=num_heads, depth=depth, seq_length=sample_length, num_tokens=num_tokens, attention_type=None)\n",
    "model_interp = model_interp.cuda()\n",
    "\n",
    "opt_interp = torch.optim.Adam(lr=lr, params=model_interp.parameters())\n",
    "sch_interp = torch.optim.lr_scheduler.LambdaLR(opt_interp, lambda i: min(i / (lr_warmup / batch_size), 1.0))\n",
    "loss_interp = torch.nn.NLLLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3257088"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTransformer(\n",
      "  (token_embedding): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (token_embedding_batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (token_embedding_activation): ReLU()\n",
      "  (pos_embedding): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (pos_embedding_batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (pos_embedding_activation): ReLU()\n",
      "  (tblocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (attention): SelfAttention(\n",
      "        (tokeys): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (toqueries): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (tovalues): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (do): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (attention): SelfAttention(\n",
      "        (tokeys): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (toqueries): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (tovalues): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (do): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (attention): SelfAttention(\n",
      "        (tokeys): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (toqueries): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (tovalues): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (do): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (attention): SelfAttention(\n",
      "        (tokeys): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (toqueries): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (tovalues): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (do): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (toprobs): Linear(in_features=256, out_features=256, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, opt, model_location):\n",
    "    checkpoint = torch.load(model_location)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    loss = checkpoint['loss']\n",
    "    epoch = checkpoint['epoch']\n",
    "    return model, opt, loss, epoch\n",
    "\n",
    "def mulawEncodeInput(inputd):\n",
    "    inputd = (librosa.mu_compress(inputd, quantize=False) + 1)/2\n",
    "    return inputd\n",
    "\n",
    "def mulawDecodeInput(output):\n",
    "    output = (output * 2) - 1\n",
    "    waveform = librosa.mu_expand(output, quantize=False)\n",
    "    return waveform\n",
    "\n",
    "def mulawEncodeTarget(inputd):\n",
    "    target = librosa.mu_compress(inputd, quantize=True) + 127\n",
    "    target = target.astype(np.long)\n",
    "    return target\n",
    "\n",
    "def mulawDecodeTarget(output):\n",
    "    output = output - 127\n",
    "    waveform = librosa.mu_expand(output, quantize=True)\n",
    "    return waveform\n",
    "\n",
    "def get_scaled_pitch(pitch):\n",
    "    return (pitch - lower_pitch_limit)/(upper_pitch_limit - lower_pitch_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(idx, start_location):\n",
    "    input_data = np.array([])\n",
    "    audio_data = np.array([])\n",
    "    \n",
    "    print(idx)\n",
    "    if idx == 'random':\n",
    "        input_data = np.random.rand((sample_length)) * 0.1\n",
    "        audio_data = input_data\n",
    "        target = np.random.rand((sample_length))\n",
    "    else:\n",
    "        start_location = int(start_location * 16000)\n",
    "\n",
    "        audio_file_name = os.path.join(data_dir, idx+'.wav')\n",
    "        audio_data, _ = librosa.load(audio_file_name, sr=sample_rate)\n",
    "        input_data = audio_data[start_location:start_location + sample_length]\n",
    "        target = audio_data[start_location + 1:start_location + 1 + sample_length]\n",
    "\n",
    "        \n",
    "    IPython.display.display(IPython.display.Audio(audio_data, rate=sample_rate))\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(8,4))\n",
    "    axes[0].plot(audio_data)\n",
    "    axes[0].set(title='Sample Length = 64000/4 secs')\n",
    "    axes[1].plot(input_data)\n",
    "    axes[1].set(title='Sample Length = 512/32 ms')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return input_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model_amplitude_interpolation(seed_id, model_interp, start_location=1.0, pitch=64, amplitude_scale=0.9, instrument_id=0, seq_len=1024, interpolation_type='step'):\n",
    "    seed, seed_target = get_data(seed_id, start_location)\n",
    "\n",
    "    new_scale = amplitude_scale\n",
    "    \n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    orig_waveform = copy.copy(seed)\n",
    "\n",
    "    input_data = mulawEncodeInput(copy.copy(seed))\n",
    "    final_sample_data = torch.from_numpy(copy.copy(input_data)).view(1, -1).cuda()\n",
    "    input_pitch = np.broadcast_to(np.array([get_scaled_pitch(pitch)]), input_data.shape)\n",
    "    scale = np.broadcast_to(np.array([new_scale]), input_data.shape)\n",
    "    instrument = np.broadcast_to(np.array([instrument_id]), input_data.shape)\n",
    "    input_data = np.stack((input_pitch, scale, instrument, input_data), axis=1)\n",
    "    input_data = torch.from_numpy(input_data).cuda()\n",
    "    \n",
    "    model_interp.eval()\n",
    "    \n",
    "    new_scale_arr = np.array([new_scale])\n",
    "    \n",
    "    # 1. Sample from model\n",
    "    with torch.no_grad():\n",
    "        for ind in range(seq_len):\n",
    "            input_data = input_data.view(1, -1, 4).float() #Convert to batch_size X seq_len X 2\n",
    "            sample_data = model_interp(input_data) #Output is batch_size X seq_length X one_hot len (256) i.e. 1 X 512 X 256. \n",
    "            \n",
    "            sample_data = sample_data[0, -1, :].argmax() #Get the last sample probabilities and argmax.\n",
    "            \n",
    "            sample_data = mulawDecodeTarget(sample_data.view(1,-1).cpu().numpy())\n",
    "            sample_data = (librosa.mu_compress(sample_data, quantize=False) + 1)/2 #Just like what we do in NSynthDataSet_RawAudio.py\n",
    "            sample_data = torch.from_numpy(sample_data).view(1,-1).cuda()\n",
    "            \n",
    "            \n",
    "            final_sample_data = torch.cat((final_sample_data, sample_data), dim=1)\n",
    "            input_data = final_sample_data[:,final_sample_data.shape[1]-sample_length:].view(1,-1)\n",
    "    \n",
    "            if interpolation_type == 'triangles':\n",
    "                \n",
    "                count = ind%(seq_len)\n",
    "                \n",
    "                if count <= (seq_len//2):\n",
    "                    new_scale = new_scale + (0.9-amplitude_scale)/(seq_len//2)\n",
    "                elif count > (seq_len//2):\n",
    "                    new_scale = new_scale - (0.9-amplitude_scale)/(seq_len//2)\n",
    "                \n",
    "                new_scale_arr = np.append(new_scale_arr, new_scale)\n",
    "                \n",
    "                scale = np.broadcast_to(np.array([new_scale]), input_data.shape)\n",
    "            \n",
    "            input_data = torch.cat((torch.from_numpy(input_pitch).view(1,-1).cuda(),\\\n",
    "                                    torch.from_numpy(scale).view(1, -1).cuda(),\\\n",
    "                                    torch.from_numpy(instrument).view(1, -1).cuda(),\\\n",
    "                                    input_data), dim=0)\n",
    "            input_data = input_data.T\n",
    "#             print('3', input_data)\n",
    "            \n",
    "    \n",
    "    final_sample_data = final_sample_data.view(-1).cpu().numpy()\n",
    "#     print(final_sample_data)\n",
    "    waveform = mulawDecodeInput(final_sample_data)\n",
    "    \n",
    "    # 2. Audio\n",
    "    IPython.display.display(IPython.display.Audio(orig_waveform, rate=sample_rate))\n",
    "    IPython.display.display(IPython.display.Audio(waveform, rate=sample_rate))\n",
    "    \n",
    "    # 3. Plot waveforms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    axes[0].plot(orig_waveform)\n",
    "    axes[0].set_title('Original Seed')\n",
    "\n",
    "    axes[1].plot(waveform[sample_length:])\n",
    "    axes[1].plot(new_scale_arr)\n",
    "    axes[1].set_title('New Sample')\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Plot spectrograms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(2,1)\n",
    "    \n",
    "    D = librosa.stft(orig_waveform, n_fft=512)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=axes[0])\n",
    "    axes[0].set(title='Orig seed')\n",
    "#     fig.colorbar(img, ax=axes[0], format=\"%+2.f dB\")\n",
    "    \n",
    "    D = librosa.stft(waveform, hop_length=390)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=axes[1])\n",
    "    axes[1].set(title='New Sample')\n",
    "#     fig.colorbar(img, ax=axes[1], format=\"%+2.f dB\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # 4. Plot spectrograms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(2,1)\n",
    "    \n",
    "    D = librosa.stft(orig_waveform, n_fft=512)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=axes[0])\n",
    "    axes[0].set(title='Orig seed')\n",
    "#     fig.colorbar(img, ax=axes[0], format=\"%+2.f dB\")\n",
    "    \n",
    "    D = librosa.stft(waveform, hop_length=390)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=axes[1])\n",
    "    axes[1].set(title='New Sample')\n",
    "#     fig.colorbar(img, ax=axes[1], format=\"%+2.f dB\")\n",
    "    plt.show()\n",
    "    print('Time taken for sampling/plotting = ', datetime.datetime.now().replace(microsecond=0) - start_time)\n",
    "    return waveform, orig_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model_instrument_interpolation(seed_id, model_interp, start_location=1.0, pitch=64, amplitude_scale=0.9, instrument_id=0, seq_len=1024, interpolation_type='step'):\n",
    "    seed, seed_target = get_data(seed_id, start_location)\n",
    "\n",
    "    new_instrument_id = 0.0\n",
    "    \n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    orig_waveform = copy.copy(seed)\n",
    "\n",
    "    input_data = mulawEncodeInput(copy.copy(seed))\n",
    "    final_sample_data = torch.from_numpy(copy.copy(input_data)).view(1, -1).cuda()\n",
    "    input_pitch = np.broadcast_to(np.array([get_scaled_pitch(pitch)]), input_data.shape)\n",
    "    scale = np.broadcast_to(np.array([amplitude_scale]), input_data.shape)\n",
    "    instrument = np.broadcast_to(np.array([new_instrument_id]), input_data.shape)\n",
    "    input_data = np.stack((input_pitch, scale, instrument, input_data), axis=1)\n",
    "    input_data = torch.from_numpy(input_data).cuda()\n",
    "    \n",
    "    model_interp.eval()\n",
    "    \n",
    "    new_instrument_id_arr = np.array([new_instrument_id])\n",
    "    \n",
    "    # 1. Sample from model\n",
    "    with torch.no_grad():\n",
    "        for ind in range(seq_len):\n",
    "            input_data = input_data.view(1, -1, 4).float() #Convert to batch_size X seq_len X 2\n",
    "            sample_data = model_interp(input_data) #Output is batch_size X seq_length X one_hot len (256) i.e. 1 X 512 X 256. \n",
    "            \n",
    "            sample_data = sample_data[0, -1, :].argmax() #Get the last sample probabilities and argmax.\n",
    "            \n",
    "            sample_data = mulawDecodeTarget(sample_data.view(1,-1).cpu().numpy())\n",
    "            sample_data = (librosa.mu_compress(sample_data, quantize=False) + 1)/2 #Just like what we do in NSynthDataSet_RawAudio.py\n",
    "            sample_data = torch.from_numpy(sample_data).view(1,-1).cuda()\n",
    "            \n",
    "            final_sample_data = torch.cat((final_sample_data, sample_data), dim=1)\n",
    "            input_data = final_sample_data[:,final_sample_data.shape[1]-sample_length:].view(1,-1)\n",
    "    \n",
    "            if interpolation_type == 'triangles':\n",
    "                \n",
    "                count = ind%(seq_len)\n",
    "                \n",
    "                if count <= (seq_len//2):\n",
    "                    new_instrument_id = new_instrument_id + (1.0)/(seq_len//2)\n",
    "                elif count > (seq_len//2):\n",
    "                    new_instrument_id = new_instrument_id - (1.0)/(seq_len//2)\n",
    "                \n",
    "                new_instrument_id_arr = np.append(new_instrument_id_arr, new_instrument_id)\n",
    "#                 print(ind, new_instrument_id)\n",
    "                    \n",
    "                instrument = np.broadcast_to(np.array([new_instrument_id]), input_data.shape)\n",
    "            \n",
    "            input_data = torch.cat((torch.from_numpy(input_pitch).view(1,-1).cuda(),\\\n",
    "                                    torch.from_numpy(scale).view(1, -1).cuda(),\\\n",
    "                                    torch.from_numpy(instrument).view(1, -1).cuda(),\\\n",
    "                                    input_data), dim=0)\n",
    "            input_data = input_data.T\n",
    "#             print('3', input_data)\n",
    "            \n",
    "    \n",
    "    final_sample_data = final_sample_data.view(-1).cpu().numpy()\n",
    "#     print(final_sample_data)\n",
    "    waveform = mulawDecodeInput(final_sample_data)\n",
    "    \n",
    "    # 2. Audio\n",
    "    IPython.display.display(IPython.display.Audio(orig_waveform, rate=sample_rate))\n",
    "    IPython.display.display(IPython.display.Audio(waveform, rate=sample_rate))\n",
    "    \n",
    "    # 3. Plot waveforms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    axes[0].plot(orig_waveform)\n",
    "    axes[0].set_title('Original Seed')\n",
    "\n",
    "    axes[1].plot(waveform[sample_length:])\n",
    "    axes[1].plot(new_instrument_id_arr)\n",
    "    axes[1].set_title('New Sample')\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Plot spectrograms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(2,1)\n",
    "    \n",
    "    D = librosa.stft(orig_waveform, n_fft=512)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=axes[0])\n",
    "    axes[0].set(title='Orig seed')\n",
    "#     fig.colorbar(img, ax=axes[0], format=\"%+2.f dB\")\n",
    "    \n",
    "    D = librosa.stft(waveform, hop_length=390)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=axes[1])\n",
    "    axes[1].set(title='New Sample')\n",
    "#     fig.colorbar(img, ax=axes[1], format=\"%+2.f dB\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # 4. Plot spectrograms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(2,1)\n",
    "    \n",
    "    D = librosa.stft(orig_waveform, n_fft=512)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=axes[0])\n",
    "    axes[0].set(title='Orig seed')\n",
    "#     fig.colorbar(img, ax=axes[0], format=\"%+2.f dB\")\n",
    "    \n",
    "    D = librosa.stft(waveform, hop_length=390)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=axes[1])\n",
    "    axes[1].set(title='New Sample')\n",
    "#     fig.colorbar(img, ax=axes[1], format=\"%+2.f dB\")\n",
    "    plt.show()\n",
    "    print('Time taken for sampling/plotting = ', datetime.datetime.now().replace(microsecond=0) - start_time)\n",
    "    return waveform, orig_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model_pitch_interpolation(seed_id, model_interp, start_location=1.0, pitch=64, amplitude_scale=0.9, instrument_id=0, seq_len=1024, interpolation_type='step'):\n",
    "    seed, seed_target = get_data(seed_id, start_location)\n",
    "    \n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    orig_waveform = copy.copy(seed)\n",
    "\n",
    "    input_data = mulawEncodeInput(copy.copy(seed))\n",
    "    final_sample_data = torch.from_numpy(copy.copy(input_data)).view(1, -1).cuda()\n",
    "    input_pitch = np.broadcast_to(np.array([get_scaled_pitch(pitch)]), input_data.shape)\n",
    "    scale = np.broadcast_to(np.array([amplitude_scale]), input_data.shape)\n",
    "    instrument = np.broadcast_to(np.array([instrument_id]), input_data.shape)\n",
    "    input_data = np.stack((input_pitch, scale, instrument, input_data), axis=1)\n",
    "    input_data = torch.from_numpy(input_data).cuda()\n",
    "    \n",
    "    \n",
    "    new_pitch = pitch\n",
    "    \n",
    "    model_interp.eval()\n",
    "    \n",
    "    # 1. Sample from model\n",
    "    with torch.no_grad():\n",
    "        for ind in range(seq_len):\n",
    "            input_data = input_data.view(1, -1, 4).float() #Convert to batch_size X seq_len X 2\n",
    "            sample_data = model_interp(input_data) #Output is batch_size X seq_length X one_hot len (256) i.e. 1 X 512 X 256. \n",
    "            \n",
    "            sample_data = sample_data[0, -1, :].argmax() #Get the last sample probabilities and argmax.\n",
    "            \n",
    "            sample_data = mulawDecodeTarget(sample_data.view(1,-1).cpu().numpy())\n",
    "            sample_data = (librosa.mu_compress(sample_data, quantize=False) + 1)/2 #Just like what we do in NSynthDataSet_RawAudio.py\n",
    "            sample_data = torch.from_numpy(sample_data).view(1,-1).cuda()\n",
    "            \n",
    "            final_sample_data = torch.cat((final_sample_data, sample_data), dim=1)\n",
    "            input_data = final_sample_data[:,final_sample_data.shape[1]-sample_length:].view(1,-1)\n",
    "    \n",
    "            if interpolation_type == 'step':\n",
    "                if ind > seq_len/2:\n",
    "                    input_pitch = np.broadcast_to(np.array([get_scaled_pitch(76)]), input_data.shape)\n",
    "            \n",
    "            if interpolation_type == 'continuous':\n",
    "                new_pitch = new_pitch + (upper_pitch_limit - pitch)/seq_len\n",
    "                \n",
    "                if ind%2000 == 0:\n",
    "                    print(ind, new_pitch)\n",
    "                input_pitch = np.broadcast_to(np.array([get_scaled_pitch(new_pitch)]), input_data.shape)\n",
    "            \n",
    "            if interpolation_type == 'triangles':\n",
    "                \n",
    "                count = ind%(seq_len)\n",
    "                \n",
    "                if count <= (seq_len//2):\n",
    "                    new_pitch = new_pitch + (upper_pitch_limit - pitch)/(seq_len//2)\n",
    "                elif count > (seq_len//2):\n",
    "                    new_pitch = new_pitch - (upper_pitch_limit - pitch)/(seq_len//2)\n",
    "                \n",
    "                input_pitch = np.broadcast_to(np.array([get_scaled_pitch(new_pitch)]), input_data.shape)\n",
    "            \n",
    "            if interpolation_type == 'triangles-2':\n",
    "                count = ind%16000\n",
    "\n",
    "                if count <= 2000:\n",
    "                    new_pitch = new_pitch + (68 - pitch)/2000\n",
    "                elif count > 2000 and count <= 4000:\n",
    "                    new_pitch = new_pitch - (68 - pitch)/2000\n",
    "                if count > 4000 and count <= 7000:\n",
    "                    new_pitch = new_pitch + (upper_pitch_limit - pitch)/3000\n",
    "                elif count > 7000 and count <= 8000:\n",
    "                    new_pitch = new_pitch\n",
    "                elif count > 8000 and count <= 11000:\n",
    "                    new_pitch = new_pitch - (upper_pitch_limit - pitch)/3000\n",
    "                elif count > 11000 and count <= 13000:\n",
    "                    new_pitch = new_pitch + (68 - pitch)/2000\n",
    "                elif count > 13000:\n",
    "                    new_pitch = new_pitch - (68 - pitch)/3000\n",
    "\n",
    "                if count == 0: \n",
    "                    new_pitch = pitch\n",
    "\n",
    "                input_pitch = np.broadcast_to(np.array([get_scaled_pitch(new_pitch)]), input_data.shape)\n",
    "                \n",
    "            input_data = torch.cat((torch.from_numpy(input_pitch).view(1,-1).cuda(),\\\n",
    "                                    torch.from_numpy(scale).view(1, -1).cuda(),\\\n",
    "                                    torch.from_numpy(instrument).view(1, -1).cuda(),\\\n",
    "                                    input_data), dim=0)\n",
    "            input_data = input_data.T\n",
    "#             print('3', input_data)\n",
    "            \n",
    "    \n",
    "    final_sample_data = final_sample_data.view(-1).cpu().numpy()\n",
    "#     print(final_sample_data)\n",
    "    waveform = mulawDecodeInput(final_sample_data)\n",
    "    \n",
    "    # 2. Audio\n",
    "    IPython.display.display(IPython.display.Audio(orig_waveform, rate=sample_rate))\n",
    "    IPython.display.display(IPython.display.Audio(waveform, rate=sample_rate))\n",
    "    \n",
    "    # 3. Plot waveforms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    axes[0].plot(orig_waveform)\n",
    "    axes[0].set_title('Original Seed')\n",
    "\n",
    "    axes[1].plot(waveform)\n",
    "    axes[1].set_title('New Sample')\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Plot spectrograms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(2,1)\n",
    "    \n",
    "    D = librosa.stft(orig_waveform, n_fft=512)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=axes[0])\n",
    "    axes[0].set(title='Orig seed')\n",
    "#     fig.colorbar(img, ax=axes[0], format=\"%+2.f dB\")\n",
    "    \n",
    "    D = librosa.stft(waveform, hop_length=390)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=axes[1])\n",
    "    axes[1].set(title='New Sample')\n",
    "#     fig.colorbar(img, ax=axes[1], format=\"%+2.f dB\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # 4. Plot spectrograms\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(2,1)\n",
    "    \n",
    "    D = librosa.stft(orig_waveform, n_fft=512)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=axes[0])\n",
    "    axes[0].set(title='Orig seed')\n",
    "#     fig.colorbar(img, ax=axes[0], format=\"%+2.f dB\")\n",
    "    \n",
    "    D = librosa.stft(waveform, hop_length=390)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=axes[1])\n",
    "    axes[1].set(title='New Sample')\n",
    "#     fig.colorbar(img, ax=axes[1], format=\"%+2.f dB\")\n",
    "    plt.show()\n",
    "    print('Time taken for sampling/plotting = ', datetime.datetime.now().replace(microsecond=0) - start_time)\n",
    "    return waveform, orig_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_interp, opt_interp, loss_interp, epoch_interp = load_model(model_interp, opt_interp, 'checkpoint/le-mc-ap-4-attention-35900.pt')\n",
    "print('Model Loaded -> ', epoch_interp, loss_interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('brass_acoustic_018-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=0, seq_len=16000, interpolation_type='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('brass_acoustic_018-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=0, seq_len=16000, interpolation_type='continuous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('brass_acoustic_018-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=0, seq_len=32000, interpolation_type='triangles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('brass_acoustic_018-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=0, seq_len=32000, interpolation_type='triangles-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('reed_acoustic_000-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=1, seq_len=16000, interpolation_type='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('reed_acoustic_000-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=1, seq_len=16000, interpolation_type='continuous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('reed_acoustic_000-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=1, seq_len=32000, interpolation_type='triangles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('reed_acoustic_000-064-a.90', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=1, seq_len=32000, interpolation_type='triangles-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero/Random Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('brass_acoustic_018-064-a.0', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=0, seq_len=32000, interpolation_type='triangles-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_pitch_interpolation('random', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=1, seq_len=32000, interpolation_type='triangles-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrument Interpolation - Brass(0) to Reed (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_instrument_interpolation('brass_acoustic_018-070-a.0', model_interp=model_interp, start_location=1, pitch=70, amplitude_scale=0.9, \\\n",
    "                                     instrument_id=0, seq_len=32000, interpolation_type='triangles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_amplitude_interpolation('reed_acoustic_000-064-a.10', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.1, \\\n",
    "                                     instrument_id=1, seq_len=2*16000, interpolation_type='triangles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, orig_seed = sample_model_amplitude_interpolation('brass_acoustic_018-064-a.10', model_interp=model_interp, start_location=1, pitch=64, amplitude_scale=0.1, \\\n",
    "                                     instrument_id=0, seq_len=2*16000, interpolation_type='triangles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
